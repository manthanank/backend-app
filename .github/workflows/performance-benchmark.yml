name: Performance Benchmark

on:
  schedule:
    - cron: '0 5 * * 1'  # Run every Monday at 5:00 AM UTC
  pull_request:
    branches: [ main ]
    types: [ labeled ]
  workflow_dispatch:  # Allow manual triggering

jobs:
  benchmark:
    runs-on: ubuntu-latest
    if: github.event_name != 'pull_request' || contains(github.event.pull_request.labels.*.name, 'benchmark')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install k6
        run: |
          curl -L https://github.com/grafana/k6/releases/download/v0.46.0/k6-v0.46.0-linux-amd64.tar.gz | tar xzf -
          sudo mv k6-v0.46.0-linux-amd64/k6 /usr/local/bin/

      - name: Start application in background
        run: |
          # Start the server with output redirection for debugging
          NODE_ENV=test PORT=3000 npm start > server.log 2>&1 &
          echo "Server started with PID $!"
          
          # Store the PID for potential troubleshooting
          echo $! > server.pid
          
          # Wait longer for the server to start - 20 seconds instead of 10
          echo "Waiting 20 seconds for server to start..."
          sleep 20

      - name: Verify server is running
        run: |
          # Check if server process is still running
          if ps -p $(cat server.pid) > /dev/null; then
            echo "Server process is running"
          else
            echo "Server process is not running. Check server.log for details"
            cat server.log
            exit 1
          fi
          
          # Try to connect to the server
          echo "Checking if server responds to requests..."
          if curl -s -f http://localhost:3000/health || curl -s -f http://localhost:3000/; then
            echo "Server is responding to requests"
          else
            echo "Server is not responding. Check server.log for details"
            cat server.log
            exit 1
          fi

      - name: Run API benchmarks
        run: |
          k6 run -o json=results.json - <<'EOT'
          import http from 'k6/http';
          import { check, sleep } from 'k6';
          
          export const options = {
            vus: 10,
            duration: '30s',
            thresholds: {
              'http_req_duration': ['p(95)<500'],
              'http_req_failed': ['rate<0.01']
            }
          };
          
          export default function() {
            const BASE_URL = 'http://localhost:3000';
            
            // Test endpoints
            check(http.get(`${BASE_URL}/api/jokes`), {
              'jokes status is 200': (r) => r.status === 200,
              'jokes response time < 200ms': (r) => r.timings.duration < 200
            });
            
            check(http.get(`${BASE_URL}/api/states`), {
              'states status is 200': (r) => r.status === 200,
              'states response time < 200ms': (r) => r.timings.duration < 200
            });
            
            sleep(1);
          }
          EOT
        
      - name: Process benchmark results
        if: always()
        run: |
          # Check if server is running - for debugging failed tests
          if [ -f server.pid ] && ps -p $(cat server.pid) > /dev/null; then
            echo "Server was still running during tests"
          else
            echo "Server was not running during tests"
            if [ -f server.log ]; then
              echo "Server log content:"
              cat server.log
            fi
          fi
          
          # Create the report if results exist
          if [ -f results.json ]; then
            echo "## Performance Benchmark Results" > benchmark-report.md
            echo "Run on $(date)" >> benchmark-report.md
            echo "### Summary" >> benchmark-report.md
            cat results.json | jq -r '"- Requests: \(.metrics.http_reqs.values.count)\n- Avg Request Duration: \(.metrics.http_req_duration.values.avg)ms\n- 95th Percentile: \(.metrics.http_req_duration.values["p(95)"])ms\n- Failure Rate: \(.metrics.http_req_failed.values.rate * 100)%"' >> benchmark-report.md
          else
            echo "## Performance Benchmark Failed" > benchmark-report.md
            echo "Run on $(date)" >> benchmark-report.md
            echo "Tests could not be completed because the server was unavailable." >> benchmark-report.md
          fi

      - name: Save benchmark results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-results
          path: |
            results.json
            benchmark-report.md
            server.log

      - name: Comment PR with benchmark results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('benchmark-report.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });